apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: rollout-strategy-example
  namespace: default
  annotations:
    serving.kserve.io/deploymentMode: "RawDeployment"
spec:
  predictor:
    model:
      modelFormat:
        name: sklearn
      storageUri: "s3://my-bucket/model"
    # Example 1: Direct deployment strategy for high availability
    # This ensures zero downtime during rollouts
    deploymentStrategy:
      type: RollingUpdate
      rollingUpdate:
        maxUnavailable: "0"      # No pods unavailable during rollout
        maxSurge: "50%"          # Can create 50% more pods during rollout
    
  transformer:
    custom:
      container:
        image: my-transformer:latest
        env:
          - name: MODEL_NAME
            value: "my-model"
    # Example 2: Resource-efficient deployment strategy
    # This prioritizes resource efficiency over availability
    deploymentStrategy:
      type: RollingUpdate
      rollingUpdate:
        maxSurge: "0"            # No extra pods during rollout
        maxUnavailable: "25%"    # Up to 25% of pods can be unavailable

---
# Example 3: Using ConfigMap defaults (no deploymentStrategy specified)
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: configmap-defaults-example
  namespace: default
  annotations:
    serving.kserve.io/deploymentMode: "RawDeployment"
spec:
  predictor:
    model:
      modelFormat:
        name: sklearn
      storageUri: "s3://my-bucket/model"
    # No deploymentStrategy specified - will use ConfigMap defaults
    # when defaultDeploymentMode is "RawDeployment" 